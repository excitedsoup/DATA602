{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b05dbf8",
   "metadata": {},
   "source": [
    "Dr. Tony Diana\n",
    "DATA 602 Introduction to Machine Learning\n",
    "Practice Exercises | Lecture Week 7\n",
    "______________________________________________________________________\n",
    "\n",
    "Ensemble Model\n",
    " \n",
    "-Use the iris data set from sklearn.\n",
    "\n",
    "-Load the iris dataset. What are the features?\n",
    "\n",
    "-Create a DataFrame of given iris dataset.\n",
    "\n",
    "-Split the dataset into training and test sets (30%).\n",
    "\n",
    "-Create a Gaussian RandomForestClassifier as clf (2,000 estimators and a depth of 2). \n",
    "\n",
    "-Determine the feature importance. Which one is the most important?\n",
    "\n",
    "-Use scikitlearn to determine the accuracy level. What is your assessment?\n",
    "\n",
    "-Use the Gradient Boosting algorithm to fit the model and predict test data.\n",
    "\n",
    "-Compute the accuracy.\n",
    "\n",
    "-Provide the feature importance.\n",
    "\n",
    "-Did the Gradient Boosting model perform better? Are there any reservations about GB and why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a3ecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#-Use the iris data set from sklearn. \n",
    "#-Load the iris dataset. What are the features?\n",
    "iris = datasets.load_iris()\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4cf753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Create a DataFrame of given iris dataset.\n",
    "df = pd.DataFrame({'sepallength': iris.data[:, 0], 'sepalwidth': iris.data[:, 1],\n",
    "                   'petallength': iris.data[:, 2], 'petalwidth': iris.data[:, 3],\n",
    "                   'species': iris.target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73035cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Split the dataset into training and test sets (30%).\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = datasets.load_iris(return_X_y = True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622ff879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, n_estimators=2000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Gaussian RandomForestClassifier as clf (2,000 estimators and a depth of 2).\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=2000, max_depth = 2)\n",
    "\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719709ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal width (cm)     0.440254\n",
       "petal length (cm)    0.435162\n",
       "sepal length (cm)    0.108361\n",
       "sepal width (cm)     0.016223\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-Determine the feature importance. Which one is the most important?\n",
    "importance = pd.Series(clf.feature_importances_, index = iris.feature_names).sort_values(ascending = False)\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02178fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#-Use scikitlearn to determine the accuracy level. What is your assessment?\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "#It seems fairly accurate, although the small dataset seems to have the thousands place and beyond as some multiple of 2/7, I'm\n",
    "#not sure if that speaks to the size of the dataset or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a0c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Use the Gradient Boosting algorithm to fit the model and predict test data.\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c8786cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-Compute the accuracy.\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a920e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal length (cm)    0.740771\n",
       "petal width (cm)     0.217854\n",
       "sepal width (cm)     0.031361\n",
       "sepal length (cm)    0.010014\n",
       "dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-Provide the feature importance.\n",
    "importance = pd.Series(model.feature_importances_, index = iris.feature_names).sort_values(ascending = False)\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552351a",
   "metadata": {},
   "source": [
    "Did the Gradient Boosting model perform better? Are there any reservations about GB and why?\n",
    "\n",
    "No, it performed slightly worse. Gradient boosting can increase computational demand, and is additionally much harder to understand in terms of how it go from one point to another."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
