{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning Example Case: \n",
    "House Sale Price Prediction (like Zillow's \"zestimate\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you see a line starting with \"TASK\", do that task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: Click on the next cell and press shift-enter\n",
    "You will get the code in it get executed.   \n",
    "The result of last command or representation of last varible in that cell will be displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/housing_processed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4628/315933477.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhousing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/housing_processed.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhousing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/housing_processed.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "housing = pd.read_csv('data/housing_processed.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Columns\n",
    "Some columns were not removed when equivalent coded ones were created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[[\"ExterQual\",\"ExterQual_Coded\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering in a series\n",
    "dtypes returns a series   \n",
    "filtering series and dataframes are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(housing.dtypes==object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.dtypes[housing.dtypes==object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.dtypes[housing.dtypes==object].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"SalePrice\" in housing.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Undesired Columns\n",
    "In my case, my colleague had left above non-numeric columns in preprocessing, after creating corresponding coded versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(housing.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could drop columns by name:\n",
    "housing_ml = housing.drop(columns=[\"ExterQual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or wholesale, keeping only numeric:\n",
    "housing_ml = housing.loc[:,housing.dtypes != object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(housing_ml.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Target into new Variable\n",
    "- \"SalePrice\" is the target.    \n",
    " - The value we want to predict from other values (features) for a house.  \n",
    "- Currently it is a column like the other features.   \n",
    "- Scikit-learn needs 2 variables: features (X) and target (y) to be Predicted into its own 1-D array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy\n",
    "- Both Pandas and scikit-learn are build on top of NumPy\n",
    "- scikit-learn can not directly work on dataframes\n",
    "- X and y data type needs to be NumPy \"ndarrays\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data as features and target\n",
    "# take \"SalePrice\" values into its own 1-D array \n",
    "sale_price = housing_ml.pop('SalePrice')\n",
    "type(sale_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop removes the column\n",
    "# \"in place\" operation\n",
    "# now housing_ml has one less column\n",
    "housing_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sale_price.values\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See what other methods are available for ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press tab after putting cursor after dot \".\"\n",
    "#y. #uncomment, press tab after . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape\n",
    "# (1460,)\n",
    "# it is equivalent to (1460)\n",
    "# means it is a 1-d array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: get ndarray version of feature dataframe put it onto variable X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_ml.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: check the shape of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: programmatically check if X and y has matching number of rows\n",
    "You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model\n",
    "Q: What would you do if you had no features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: You would always estimatate the average house price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have to do much better than that.  \n",
    "We have so much data to base our decision on.   \n",
    "It can still serve us as a baseline to compare.   \n",
    "An inferior baseline could be: random in the range or max and min in training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import estimator\n",
    "import sklearn\n",
    "from sklearn.dummy import DummyRegressor\n",
    "# Instantiate estimator\n",
    "# guess the mean every single time\n",
    "mean_reg = DummyRegressor(strategy='mean')\n",
    "# fit estimator\n",
    "mean_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "mean_reg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating The Model\n",
    "scikit-learn regressors have a score function.   \n",
    "It gives you how much better your model does compared to worst model\n",
    "Technically: what percentage of the variance has decreased over the worst model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Mean\" *is* the worst model, so its score will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reg.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a linear model \n",
    "First, let's use only one feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lf = housing_ml[['LotFrontage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(X_lf, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you see that it used defaults to create the estimator.   \n",
    "You could google \"LinearRegression sklearn\" and find the documentation:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "to see the options for the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_model.predict(X_lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.score(X_lf, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart Showing the Linear Fit\n",
    "matplotlib is the most common visualization library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(y, y_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_lf,y)\n",
    "plt.plot(X_lf,y_pred,'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: add labels to these charts\n",
    "search label:\n",
    "https://matplotlib.org/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: try replacing scatter with plot\n",
    "Do you see why scatter is needed for data rows.\n",
    "Try also replacing plot with scatter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of using a Better predictor \n",
    "Ground Living Area should be better than Lot Frontage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_area = housing_ml[['GrLivArea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(X_area, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the linear_model has another model in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = linear_model.predict(X_area)\n",
    "linear_model.score(X_area, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(y, y_pred2); # blue obviously better\n",
    "plt.scatter(y, y_pred); # orange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: add legend\n",
    "which color is the prediction based on which feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We had 81 columns (80 features) in original dataset,\n",
    "# coded as 221 features!\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = linear_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(y_pred3, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 21\n",
    "train_size = .8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27342162073249154"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "X_lf = housing_ml[['YearBuilt']]\n",
    "linear_model.fit(X_lf, y)\n",
    "y_pred = linear_model.predict(X_lf)\n",
    "linear_model.score(X_lf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in housing_ml.columns:\n",
    "    linear_model = LinearRegression()\n",
    "    X_lf = housing_ml[[feature]]\n",
    "    linear_model.fit(X_lf, y)\n",
    "    y_pred = linear_model.predict(X_lf)\n",
    "    linear_model.score(X_lf, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best prediction is from OverallQual giving an error score of 0.6454631197278842\n",
      "Top 10 error:\n",
      "1 OverallQual 49018.435788124996, score: 0.6454631197278842\n",
      "2 ExterQual_Coded 58260.14865535066, score: 0.4991753471267154\n",
      "3 GrLivArea 61369.55515927838, score: 0.444289666781406\n",
      "4 KitchenQual_Coded 61622.30113827634, score: 0.43970293723342646\n",
      "5 TotalBsmtSF 62430.331675814006, score: 0.42491266111423975\n",
      "6 1stFlrSF 62876.2562386846, score: 0.4166679048480356\n",
      "7 GarageCars 63131.022100901646, score: 0.41193116659665807\n",
      "8 GarageArea 63377.71018105261, score: 0.4073263621599067\n",
      "9 BsmtQual_Coded 66831.5181312807, score: 0.3409700148262619\n",
      "10 GarageFinish_Coded 68071.65468394081, score: 0.3162849544224505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "mseDict = {}\n",
    "scoreDict = {}\n",
    "for feature in housing_ml.columns:\n",
    "    linear_model = LinearRegression()\n",
    "    X_lf = housing_ml[[feature]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_lf, y, train_size = .8, random_state = 21)\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    y_pred = linear_model.predict(X_test)\n",
    "    mseDict[feature] = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    scoreDict[feature] = linear_model.score(X_test, y_test)\n",
    "\n",
    "mseDict = sorted(mseDict.items(), key=lambda x: x[1])\n",
    "scoreDict = sorted(scoreDict.items(), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "top10 = mseDict[:10]\n",
    "top10score = scoreDict[:10]\n",
    "#print(top10score)\n",
    "print('The best prediction is from', top10score[0][0], 'giving an error score of', top10score[0][1])\n",
    "print('Top 10 error:')\n",
    "\n",
    "i = 1\n",
    "for p in top10:\n",
    "    print(str(i), ' ', top10[i-1][0], ' ', top10[i-1][1], ', score: ', top10score[i-1][1], sep = '')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best prediction is from Model: 5 giving an error score of 0.7173882583039418\n",
      "Top 10 error:\n",
      "1 Model: 5 43764.68831784155, score: 0.7173882583039418\n",
      "2 Model: 4 44577.66409611639, score: 0.706791108152437\n",
      "3 Model: 2 45673.46700931651, score: 0.6921986779040229\n",
      "4 Model: 7 46468.13490082075, score: 0.6813946935673894\n",
      "5 Model: 3 47070.07230442364, score: 0.6730869536074611\n",
      "6 Model: 6 47124.910051666164, score: 0.6723247870365775\n",
      "7 Model: 1 47433.82463056837, score: 0.6680147343521529\n",
      "8 Model: 8 48237.754631121876, score: 0.6566660974647345\n",
      "9 Model: 9 48571.27166300009, score: 0.6519020465859777\n",
      "10 Model: 13 49640.643170742085, score: 0.6364054863411375\n"
     ]
    }
   ],
   "source": [
    "top10head = []\n",
    "for predictor in top10:\n",
    "    top10head.append(predictor[0])\n",
    "\n",
    "group45 = []\n",
    "c = 1\n",
    "\n",
    "for predictor in top10head:\n",
    "    for index in range(c,10):\n",
    "        group45.append([predictor, top10head[index]])\n",
    "    c+=1\n",
    "    \n",
    "mseDict2 = {}\n",
    "scoreDict2 = {}\n",
    "n = 1\n",
    "\n",
    "for pair in group45:\n",
    "    linear_model = LinearRegression()\n",
    "    X_lf = housing_ml[[pair[0], pair[1]]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_lf, y, train_size = .8, random_state = 21)\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    y_pred = linear_model.predict(X_test)\n",
    "    mseDict2['Model: ' + str(n)] = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    scoreDict2['Model: ' + str(n)] = linear_model.score(X_test, y_test)\n",
    "    n += 1\n",
    "\n",
    "mseDict2 = sorted(mseDict2.items(), key=lambda x: x[1])\n",
    "scoreDict2 = sorted(scoreDict2.items(), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "top10_2 = mseDict2[:10]\n",
    "top10score2 = scoreDict2[:10]\n",
    "#print(top10score2)\n",
    "print()\n",
    "print('The best prediction is from', top10score2[0][0], 'giving an error score of', top10score2[0][1])\n",
    "print('Top 10 error:')\n",
    "\n",
    "i = 1\n",
    "for p in top10_2:\n",
    "    print(str(i), ' ', top10_2[i-1][0], ' ', top10_2[i-1][1], ', score: ', top10score2[i-1][1], sep = '')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model all features:\n",
      "Mean Squared Error: 35623.303450008585\n",
      "Score: 0.8127547098527779\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "X_lf = housing_ml\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lf, y, train_size = .8, random_state = 21)\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred = linear_model.predict(X_test)\n",
    "allMSE = mean_squared_error(y_test, y_pred, squared = False)\n",
    "allScore = linear_model.score(X_test, y_test)\n",
    "print('Linear model all features:')\n",
    "print('Mean Squared Error:', allMSE)\n",
    "print('Score:', allScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNR5:\n",
      "Mean Squared Error: 51966.07983368139\n",
      "0.6015421069563245\n"
     ]
    }
   ],
   "source": [
    "KNR_model = KNeighborsRegressor(n_neighbors=5)\n",
    "X_lf = housing_ml\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lf, y, train_size = .8, random_state = 21)\n",
    "KNR_model.fit(X_train, y_train)\n",
    "y_pred = KNR_model.predict(X_test)\n",
    "knr5MSE = mean_squared_error(y_test, y_pred, squared = False)\n",
    "knr5Score = KNR_model.score(X_test, y_test)\n",
    "print('KNR5:')\n",
    "print('Mean Squared Error:', knr5MSE)\n",
    "print(knr5Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNR10:\n",
      "Mean Squared Error: 52392.16317256475\n",
      "Score: 0.5949812006956909\n"
     ]
    }
   ],
   "source": [
    "KNR_model = KNeighborsRegressor(n_neighbors=10)\n",
    "X_lf = housing_ml\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lf, y, train_size = .8, random_state = 21)\n",
    "KNR_model.fit(X_train, y_train)\n",
    "y_pred = KNR_model.predict(X_test)\n",
    "knr10MSE = mean_squared_error(y_test, y_pred, squared = False)\n",
    "knr10Score = KNR_model.score(X_test, y_test)\n",
    "print('KNR10:')\n",
    "print('Mean Squared Error:', knr10MSE)\n",
    "print('Score:', knr10Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression, when using all features seems to perform the best\n"
     ]
    }
   ],
   "source": [
    "print('Linear regression, when using all features seems to perform the best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
